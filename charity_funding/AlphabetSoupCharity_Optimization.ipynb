{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "KCeyOum-TQ1V"
   },
   "outputs": [],
   "source": [
    "# imported from google colab\n",
    "#https://colab.research.google.com/drive/19b5Hn1BLEva9jNn5mWisg69YmXPjqa6o#scrollTo=VgwkAX-8WdDI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jgtBmJ9TWWz"
   },
   "source": [
    "Step 3: Optimize the Model\n",
    "Using your knowledge of TensorFlow, optimize your model to achieve a target predictive accuracy higher than 75%.\n",
    "\n",
    "Use any or all of the following methods to optimize your model:\n",
    "\n",
    "Adjust the input data to ensure that no variables or outliers are causing confusion in the model, such as:\n",
    "Dropping more or fewer columns.\n",
    "Creating more bins for rare occurrences in columns.\n",
    "Increasing or decreasing the number of values for each bin.\n",
    "Add more neurons to a hidden layer.\n",
    "Add more hidden layers.\n",
    "Use different activation functions for the hidden layers.\n",
    "Add or reduce the number of epochs to the training regimen.\n",
    "Note: If you make at least three attempts at optimizing your model, you will not lose points if your model does not achieve target performance.\n",
    "\n",
    "Create a new Google Colab file and name it AlphabetSoupCharity_Optimization.ipynb.\n",
    "\n",
    "Import your dependencies and read in the charity_data.csv to a Pandas DataFrame.\n",
    "\n",
    "Preprocess the dataset as you did in Step 1. Be sure to adjust for any modifications that came out of optimizing the model.\n",
    "\n",
    "Design a neural network model, and be sure to adjust for modifications that will optimize the model to achieve higher than 75% accuracy.\n",
    "\n",
    "Save and export your results to an HDF5 file. Name the file AlphabetSoupCharity_Optimization.h5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "WvfBh5MbTZFj",
    "outputId": "a5b5272e-e1e2-4b23-eb97-7c263b77225c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 13:46:18.107882: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd\n",
    "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ohajuKhNVo7g"
   },
   "outputs": [],
   "source": [
    "# categorical = APPLICATION_TYPE, AFFILIATION, CLASSIFICATION, USE_CASE, ORGANIZATION, 'INCOME_AMT,' SPECIAL_CONSIDERATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UqiXdPmgVwie",
    "outputId": "4600741f-c714-40f3-f609-cf468aee1569"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34299, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "iXbcx1hAVx_R",
    "outputId": "fe1574d1-ce6c-462f-b18b-1aa103b510bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EIN                        int64\n",
       "NAME                      object\n",
       "APPLICATION_TYPE          object\n",
       "AFFILIATION               object\n",
       "CLASSIFICATION            object\n",
       "USE_CASE                  object\n",
       "ORGANIZATION              object\n",
       "STATUS                     int64\n",
       "INCOME_AMT                object\n",
       "SPECIAL_CONSIDERATIONS    object\n",
       "ASK_AMT                    int64\n",
       "IS_SUCCESSFUL              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100
    },
    "id": "vNnJUJVCV0ii",
    "outputId": "894f7a47-f1eb-417f-afef-c24c0f477894"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE  AFFILIATION CLASSIFICATION    USE_CASE ORGANIZATION  \\\n",
       "0              T10  Independent          C1000  ProductDev  Association   \n",
       "\n",
       "   STATUS INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0       1          0                      N     5000              1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_df = application_df.drop(columns = ['EIN', 'NAME'])\n",
    "application_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "id": "63-TBOwTV2xS",
    "outputId": "da2c1129-9d48-4f85-dbd0-8ead76a2dd76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE            17\n",
       "AFFILIATION                  6\n",
       "CLASSIFICATION              71\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "STATUS                       2\n",
       "INCOME_AMT                   9\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "application_df.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "UqySljg9V4h-",
    "outputId": "18e87588-019a-43b7-af9e-b129e200f6c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE\n",
       "T3     27037\n",
       "T4      1542\n",
       "T6      1216\n",
       "T5      1173\n",
       "T19     1065\n",
       "T8       737\n",
       "T7       725\n",
       "T10      528\n",
       "T9       156\n",
       "T13       66\n",
       "T12       27\n",
       "T2        16\n",
       "T25        3\n",
       "T14        3\n",
       "T29        2\n",
       "T15        2\n",
       "T17        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at APPLICATION_TYPE value counts to identify and replace with \"Other\"\n",
    "value_counts_APPTYPE = application_df['APPLICATION_TYPE'].value_counts()\n",
    "value_counts_APPTYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-VtwnWvMV6iz",
    "outputId": "03d2b4ce-3d5e-4202-ff82-c94a2e96ff62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T12\n",
      "T2\n",
      "T25\n",
      "T14\n",
      "T29\n",
      "T15\n",
      "T17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [print(APPTYPE) for x in application_df['APPLICATION_TYPE'].value_counts() if x<50]\n",
    "\n",
    "[print(APPTYPE) for APPTYPE, count in zip(value_counts_APPTYPE.index, value_counts_APPTYPE.values) if count<50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "XEuygT_ZV8uB",
    "outputId": "b8a46fd1-d41b-417e-9a10-2ad074b4d97e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE\n",
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "T8         737\n",
       "T7         725\n",
       "T10        528\n",
       "T9         156\n",
       "T13         66\n",
       "Other       54\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "# use the variable name `application_types_to_replace`\n",
    "application_types_to_replace = []\n",
    "[application_types_to_replace.append(APPTYPE) for APPTYPE, count in zip(value_counts_APPTYPE.index, value_counts_APPTYPE.values) if count<50]\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
    "\n",
    "# Check to make sure replacement was successful\n",
    "application_df['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RIjMPu3MV-1B",
    "outputId": "9e264abe-3c25-4e86-e3f1-8d7550e81e56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('C1000', 17326), ('C2000', 6074), ('C1200', 4837), ('C3000', 1918), ('C2100', 1883), ('C7000', 777), ('C1700', 287), ('C4000', 194), ('C5000', 116), ('C1270', 114), ('C2700', 104), ('C2800', 95), ('C7100', 75), ('C1300', 58), ('C1280', 50), ('C1230', 36), ('C1400', 34), ('C7200', 32), ('C2300', 32), ('C1240', 30), ('C8000', 20), ('C7120', 18), ('C1500', 16), ('C1800', 15), ('C6000', 15), ('C1250', 14), ('C8200', 11), ('C1238', 10), ('C1278', 10), ('C1235', 9), ('C1237', 9), ('C7210', 7), ('C2400', 6), ('C1720', 6), ('C4100', 6), ('C1257', 5), ('C1600', 5), ('C1260', 3), ('C2710', 3), ('C0', 3), ('C3200', 2), ('C1234', 2), ('C1246', 2), ('C1267', 2), ('C1256', 2), ('C2190', 1), ('C4200', 1), ('C2600', 1), ('C5200', 1), ('C1370', 1), ('C1248', 1), ('C6100', 1), ('C1820', 1), ('C1900', 1), ('C1236', 1), ('C3700', 1), ('C2570', 1), ('C1580', 1), ('C1245', 1), ('C2500', 1), ('C1570', 1), ('C1283', 1), ('C2380', 1), ('C1732', 1), ('C1728', 1), ('C2170', 1), ('C4120', 1), ('C8210', 1), ('C2561', 1), ('C4500', 1), ('C2150', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Look at CLASSIFICATION value counts to identify and replace with \"Other\"\n",
    "value_counts_CLASS = application_df['CLASSIFICATION'].value_counts()\n",
    "print(list(zip(value_counts_CLASS.index, value_counts_CLASS.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "id": "sS_HZWPuWA_N",
    "outputId": "44db1ba4-69e8-484a-e8e2-524611e571a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE            11\n",
       "AFFILIATION                  6\n",
       "CLASSIFICATION              71\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "STATUS                       2\n",
       "INCOME_AMT                   9\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "id": "EgCSIDCGWCac",
    "outputId": "b11b43a3-04d9-4f7b-9e78-f33509956781"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASSIFICATION\n",
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "Other     1003\n",
       "C7000      777\n",
       "C1700      287\n",
       "C4000      194\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "classifications_to_replace = []\n",
    "[classifications_to_replace.append(CLASSTYPE) for CLASSTYPE, count in zip(value_counts_CLASS.index, value_counts_CLASS.values) if count < 190]\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "\n",
    "# Check to make sure replacement was successful\n",
    "application_df['CLASSIFICATION'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "id": "0kT9JXwAWE78",
    "outputId": "7fd94c2e-e7b8-4652-8ca9-00c3adb94d99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE            11\n",
       "AFFILIATION                  6\n",
       "CLASSIFICATION               9\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "STATUS                       2\n",
       "INCOME_AMT                   9\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "-vJHNHlmWGW1"
   },
   "outputs": [],
   "source": [
    "application_df['INCOME_AMT'] =application_df['INCOME_AMT'].astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HCSe1HucWH-A",
    "outputId": "78bba873-a572-415c-b521-fe7e206b414e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATUS                             2\n",
       "ASK_AMT                         8747\n",
       "IS_SUCCESSFUL                      2\n",
       "APPLICATION_TYPE_Other             2\n",
       "APPLICATION_TYPE_T10               2\n",
       "APPLICATION_TYPE_T13               2\n",
       "APPLICATION_TYPE_T19               2\n",
       "APPLICATION_TYPE_T3                2\n",
       "APPLICATION_TYPE_T4                2\n",
       "APPLICATION_TYPE_T5                2\n",
       "APPLICATION_TYPE_T6                2\n",
       "APPLICATION_TYPE_T7                2\n",
       "APPLICATION_TYPE_T8                2\n",
       "APPLICATION_TYPE_T9                2\n",
       "AFFILIATION_CompanySponsored       2\n",
       "AFFILIATION_Family/Parent          2\n",
       "AFFILIATION_Independent            2\n",
       "AFFILIATION_National               2\n",
       "AFFILIATION_Other                  2\n",
       "AFFILIATION_Regional               2\n",
       "CLASSIFICATION_C1000               2\n",
       "CLASSIFICATION_C1200               2\n",
       "CLASSIFICATION_C1700               2\n",
       "CLASSIFICATION_C2000               2\n",
       "CLASSIFICATION_C2100               2\n",
       "CLASSIFICATION_C3000               2\n",
       "CLASSIFICATION_C4000               2\n",
       "CLASSIFICATION_C7000               2\n",
       "CLASSIFICATION_Other               2\n",
       "USE_CASE_CommunityServ             2\n",
       "USE_CASE_Heathcare                 2\n",
       "USE_CASE_Other                     2\n",
       "USE_CASE_Preservation              2\n",
       "USE_CASE_ProductDev                2\n",
       "ORGANIZATION_Association           2\n",
       "ORGANIZATION_Co-operative          2\n",
       "ORGANIZATION_Corporation           2\n",
       "ORGANIZATION_Trust                 2\n",
       "INCOME_AMT_0                       2\n",
       "INCOME_AMT_1-9999                  2\n",
       "INCOME_AMT_10000-24999             2\n",
       "INCOME_AMT_100000-499999           2\n",
       "INCOME_AMT_10M-50M                 2\n",
       "INCOME_AMT_1M-5M                   2\n",
       "INCOME_AMT_25000-99999             2\n",
       "INCOME_AMT_50M+                    2\n",
       "INCOME_AMT_5M-10M                  2\n",
       "SPECIAL_CONSIDERATIONS_N           2\n",
       "SPECIAL_CONSIDERATIONS_Y           2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "categorical_series = ['APPLICATION_TYPE', 'AFFILIATION', 'CLASSIFICATION', 'USE_CASE', 'ORGANIZATION','INCOME_AMT', 'SPECIAL_CONSIDERATIONS']\n",
    "application_df_dummies = pd.get_dummies(application_df, columns=categorical_series)\n",
    "application_df_dummies.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "vPuYdl_QWJtS"
   },
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = application_df_dummies['IS_SUCCESSFUL'].values\n",
    "target_removed_df = application_df_dummies.copy()\n",
    "target_removed_df.drop(['IS_SUCCESSFUL'], axis=1)\n",
    "X = target_removed_df.values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "e8PsOcY-WL5j"
   },
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "OR7pVb6rWQA3",
    "outputId": "a71651ec-2bd1-4e88-f3a9-808ac1d0b887"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dev/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m45\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">451</span> (1.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m451\u001b[0m (1.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">451</span> (1.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m451\u001b[0m (1.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  8\n",
    "hidden_nodes_layer2 = 5\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "z0jzEjtkWTF7"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3cloHLLWbTJ",
    "outputId": "89f6abb2-a38b-4f1f-b779-17d796219be5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 912us/step - accuracy: 0.8025 - loss: 0.4488\n",
      "Epoch 2/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896us/step - accuracy: 0.9973 - loss: 0.0202\n",
      "Epoch 3/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 958us/step - accuracy: 0.9978 - loss: 0.0076\n",
      "Epoch 4/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 975us/step - accuracy: 0.9987 - loss: 0.0033\n",
      "Epoch 5/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 987us/step - accuracy: 0.9989 - loss: 0.0020\n",
      "Epoch 6/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0018\n",
      "Epoch 7/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 0.0011\n",
      "Epoch 8/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9999 - loss: 7.5429e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 970us/step - accuracy: 0.9999 - loss: 5.0432e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 932us/step - accuracy: 0.9999 - loss: 5.9444e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 978us/step - accuracy: 1.0000 - loss: 3.0869e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - accuracy: 0.9998 - loss: 4.4818e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 998us/step - accuracy: 0.9999 - loss: 3.7265e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 966us/step - accuracy: 1.0000 - loss: 2.2930e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 922us/step - accuracy: 0.9999 - loss: 2.7773e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741us/step - accuracy: 0.9999 - loss: 3.4081e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677us/step - accuracy: 0.9999 - loss: 2.4827e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - accuracy: 1.0000 - loss: 1.1148e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - accuracy: 0.9999 - loss: 2.2532e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 0.9999 - loss: 2.5653e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - accuracy: 1.0000 - loss: 1.8106e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - accuracy: 0.9999 - loss: 2.4696e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - accuracy: 0.9999 - loss: 2.9571e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 732us/step - accuracy: 0.9999 - loss: 2.3463e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676us/step - accuracy: 0.9999 - loss: 2.2265e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - accuracy: 0.9999 - loss: 3.6767e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 1.0000 - loss: 1.8477e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - accuracy: 0.9999 - loss: 2.3600e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 752us/step - accuracy: 0.9999 - loss: 3.3710e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - accuracy: 0.9999 - loss: 3.1020e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - accuracy: 1.0000 - loss: 1.8243e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 1.0000 - loss: 9.1429e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - accuracy: 1.0000 - loss: 1.3435e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - accuracy: 1.0000 - loss: 1.4746e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - accuracy: 1.0000 - loss: 1.3553e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 1.0000 - loss: 4.3495e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 683us/step - accuracy: 1.0000 - loss: 7.0349e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.5797e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - accuracy: 0.9998 - loss: 3.1872e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9999 - loss: 3.0106e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 0.9999 - loss: 3.3433e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803us/step - accuracy: 1.0000 - loss: 6.0826e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step - accuracy: 1.0000 - loss: 6.2572e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 922us/step - accuracy: 1.0000 - loss: 1.7712e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 973us/step - accuracy: 1.0000 - loss: 1.6277e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 908us/step - accuracy: 1.0000 - loss: 6.8289e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 987us/step - accuracy: 1.0000 - loss: 1.7517e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - accuracy: 0.9999 - loss: 3.4616e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - accuracy: 0.9999 - loss: 2.6202e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 737us/step - accuracy: 1.0000 - loss: 9.0858e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 1.0000 - loss: 1.5325e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 1.0000 - loss: 2.8522e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - accuracy: 1.0000 - loss: 4.8907e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - accuracy: 1.0000 - loss: 1.0486e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 773us/step - accuracy: 1.0000 - loss: 1.4255e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 788us/step - accuracy: 1.0000 - loss: 1.7876e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - accuracy: 1.0000 - loss: 4.4694e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676us/step - accuracy: 1.0000 - loss: 1.4808e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - accuracy: 1.0000 - loss: 1.3151e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - accuracy: 1.0000 - loss: 1.7359e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - accuracy: 0.9999 - loss: 3.7065e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - accuracy: 1.0000 - loss: 1.7588e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 757us/step - accuracy: 0.9999 - loss: 2.5590e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - accuracy: 1.0000 - loss: 3.8509e-05\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - accuracy: 1.0000 - loss: 5.6975e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - accuracy: 1.0000 - loss: 6.2509e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - accuracy: 0.9999 - loss: 2.4907e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/step - accuracy: 1.0000 - loss: 1.1863e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - accuracy: 0.9999 - loss: 4.4814e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 1.0000 - loss: 1.1073e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 746us/step - accuracy: 1.0000 - loss: 1.2367e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.9999 - loss: 2.6858e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 739us/step - accuracy: 1.0000 - loss: 3.8911e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 688us/step - accuracy: 1.0000 - loss: 1.0514e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673us/step - accuracy: 1.0000 - loss: 7.4499e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - accuracy: 1.0000 - loss: 1.1308e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 0.9999 - loss: 3.8231e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 1.0000 - loss: 8.8757e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 688us/step - accuracy: 0.9999 - loss: 4.3881e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674us/step - accuracy: 1.0000 - loss: 1.0091e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 1.0000 - loss: 5.0671e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 683us/step - accuracy: 1.0000 - loss: 1.4078e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 1.0000 - loss: 1.5891e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673us/step - accuracy: 0.9999 - loss: 2.6708e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 748us/step - accuracy: 1.0000 - loss: 1.3368e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - accuracy: 1.0000 - loss: 8.8135e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 732us/step - accuracy: 1.0000 - loss: 2.0896e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 737us/step - accuracy: 0.9999 - loss: 2.7515e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - accuracy: 1.0000 - loss: 6.6836e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 1.0000 - loss: 1.0248e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - accuracy: 1.0000 - loss: 1.4578e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.9998 - loss: 6.2952e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - accuracy: 1.0000 - loss: 2.0787e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - accuracy: 0.9999 - loss: 1.8511e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - accuracy: 1.0000 - loss: 1.2641e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - accuracy: 1.0000 - loss: 1.2417e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - accuracy: 1.0000 - loss: 4.8604e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - accuracy: 1.0000 - loss: 2.0550e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - accuracy: 1.0000 - loss: 1.2441e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - accuracy: 1.0000 - loss: 1.0345e-04\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82AAErD0WcJy",
    "outputId": "87a3cd68-6695-44ab-8514-482a09ec63f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - 876us/step - accuracy: 0.9997 - loss: 0.0030\n",
      "Loss: 0.0029633950907737017, Accuracy: 0.9996501207351685\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ZStergnWcei",
    "outputId": "f7a2bdf0-277c-492a-f724-063ffbf5d161"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Export our model to HDF5 file - AlphabetSoupCharity.h5\n",
    "nn.save('AlphabetSoupCharity.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "M-qOdkH0WklF",
    "outputId": "855958f4-74fa-40e0-be6d-a4d1b6c2ee9b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df = pd.DataFrame(fit_model.history)\n",
    "\n",
    "# Increase the index by 1 to match the number of epochs\n",
    "history_df.index += 1\n",
    "\n",
    "# Plot the loss\n",
    "history_df.plot(y=\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "nhNqFTKNWcr6",
    "outputId": "bef2e619-c757-4f6d-8aa4-4fc8941d5b8a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df = pd.DataFrame(fit_model.history, index=range(1,len(fit_model.history[\"loss\"])+1))\n",
    "\n",
    "# Plot the accuracy\n",
    "history_df.plot(y=\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j47f9qGyWc4u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aeu7UWDoXhtJ"
   },
   "source": [
    "second model - more hidden layers - pyramid style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "id": "VgwkAX-8WdDI",
    "outputId": "29228cdf-6e13-4ebf-d1f5-91519893eca6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dev/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,560</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m576\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │         \u001b[38;5;34m1,560\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m5\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,641</span> (10.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,641\u001b[0m (10.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,641</span> (10.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,641\u001b[0m (10.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features_b = len(X_train[0])\n",
    "hidden_nodes_layer1_b =  8\n",
    "hidden_nodes_layer2_b = 64\n",
    "hidden_nodes_layer3_b = 24\n",
    "hidden_nodes_layer4_b = 4\n",
    "\n",
    "nn_b = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_b.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1_b, input_dim=number_input_features_b, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn_b.add(tf.keras.layers.Dense(units=hidden_nodes_layer2_b, activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Third hidden layer\n",
    "nn_b.add(tf.keras.layers.Dense(units=hidden_nodes_layer3_b, activation=\"relu\"))\n",
    "\n",
    "# fourth hidden layer\n",
    "nn_b.add(tf.keras.layers.Dense(units=hidden_nodes_layer4_b, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_b.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "NQb6vOlpWdNo"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_b.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ZPQr8hNW_Qt",
    "outputId": "5d4d6536-ca8c-4769-c243-5986c5d8c5f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8942 - loss: 0.2671\n",
      "Epoch 2/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 995us/step - accuracy: 0.9983 - loss: 0.0156\n",
      "Epoch 3/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0042\n",
      "Epoch 4/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 981us/step - accuracy: 0.9993 - loss: 0.0052\n",
      "Epoch 5/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 967us/step - accuracy: 0.9992 - loss: 0.0034\n",
      "Epoch 6/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 985us/step - accuracy: 0.9997 - loss: 7.7361e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 988us/step - accuracy: 0.9999 - loss: 4.4167e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 954us/step - accuracy: 1.0000 - loss: 2.7645e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 949us/step - accuracy: 0.9999 - loss: 2.7576e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 962us/step - accuracy: 0.9999 - loss: 7.9898e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 993us/step - accuracy: 1.0000 - loss: 2.3805e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.6322e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.0391e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9999 - loss: 0.0012\n",
      "Epoch 15/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0016\n",
      "Epoch 16/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 7.6144e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9993 - loss: 6.2962e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 3.4459e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 961us/step - accuracy: 0.9992 - loss: 7.2368e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 967us/step - accuracy: 0.9994 - loss: 7.7966e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 4.6761e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 988us/step - accuracy: 1.0000 - loss: 2.1170e-06\n",
      "Epoch 23/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.4245e-07\n",
      "Epoch 24/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.2110e-07\n",
      "Epoch 25/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.0514e-07\n",
      "Epoch 26/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.9033e-07\n",
      "Epoch 27/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.4315e-07\n",
      "Epoch 28/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.9256e-07\n",
      "Epoch 29/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.3944e-07\n",
      "Epoch 30/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.7716e-08\n",
      "Epoch 31/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 995us/step - accuracy: 1.0000 - loss: 3.9845e-08\n",
      "Epoch 32/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 987us/step - accuracy: 1.0000 - loss: 1.9713e-08\n",
      "Epoch 33/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 962us/step - accuracy: 1.0000 - loss: 1.6439e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 993us/step - accuracy: 1.0000 - loss: 4.5363e-08\n",
      "Epoch 35/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.3354e-08\n",
      "Epoch 36/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.1361e-08\n",
      "Epoch 37/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.2872e-08\n",
      "Epoch 38/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.1554e-08\n",
      "Epoch 39/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.1531e-08\n",
      "Epoch 40/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.3680e-08\n",
      "Epoch 41/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.2153e-09\n",
      "Epoch 42/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.7530e-09\n",
      "Epoch 43/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.2293e-09\n",
      "Epoch 44/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.1784e-09\n",
      "Epoch 45/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.1572e-09\n",
      "Epoch 46/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.0897e-09\n",
      "Epoch 47/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.1238e-09\n",
      "Epoch 48/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.0014e-09\n",
      "Epoch 49/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.1615e-09\n",
      "Epoch 50/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.7750e-09\n",
      "Epoch 51/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.3536e-10\n",
      "Epoch 52/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 971us/step - accuracy: 1.0000 - loss: 8.2297e-10\n",
      "Epoch 53/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 977us/step - accuracy: 1.0000 - loss: 7.4005e-10\n",
      "Epoch 54/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 959us/step - accuracy: 1.0000 - loss: 5.2149e-10\n",
      "Epoch 55/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.0568e-10\n",
      "Epoch 56/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.0599e-09\n",
      "Epoch 57/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.1231e-10\n",
      "Epoch 58/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.5666e-10\n",
      "Epoch 59/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.3742e-10\n",
      "Epoch 60/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.8305e-10\n",
      "Epoch 61/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.9242e-10\n",
      "Epoch 62/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.8650e-10\n",
      "Epoch 63/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.8312e-10\n",
      "Epoch 64/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.7638e-11\n",
      "Epoch 65/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.5734e-11\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 987us/step - accuracy: 1.0000 - loss: 6.9283e-11\n",
      "Epoch 67/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 995us/step - accuracy: 1.0000 - loss: 8.6609e-11\n",
      "Epoch 68/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.2416e-11\n",
      "Epoch 69/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 999us/step - accuracy: 1.0000 - loss: 3.8890e-11\n",
      "Epoch 70/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.6553e-11\n",
      "Epoch 71/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.0943e-11\n",
      "Epoch 72/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.3170e-11  \n",
      "Epoch 73/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.2604e-11\n",
      "Epoch 74/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.5744e-11\n",
      "Epoch 75/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.7902e-11\n",
      "Epoch 76/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 991us/step - accuracy: 1.0000 - loss: 2.2971e-11\n",
      "Epoch 77/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 972us/step - accuracy: 1.0000 - loss: 4.0174e-11\n",
      "Epoch 78/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.8212e-11\n",
      "Epoch 79/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 988us/step - accuracy: 1.0000 - loss: 2.9545e-11\n",
      "Epoch 80/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 998us/step - accuracy: 1.0000 - loss: 2.7101e-11\n",
      "Epoch 81/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.2860e-11\n",
      "Epoch 82/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.4878e-11\n",
      "Epoch 83/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.0274e-11\n",
      "Epoch 84/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.2155e-11\n",
      "Epoch 85/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.2096e-11\n",
      "Epoch 86/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 984us/step - accuracy: 1.0000 - loss: 1.3632e-11\n",
      "Epoch 87/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.4623e-11\n",
      "Epoch 88/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.5441e-11\n",
      "Epoch 89/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.1225e-11\n",
      "Epoch 90/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.4070e-11  \n",
      "Epoch 91/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.0784e-11\n",
      "Epoch 92/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.7438e-11\n",
      "Epoch 93/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.1134e-11\n",
      "Epoch 94/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.4416e-11\n",
      "Epoch 95/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.3187e-11\n",
      "Epoch 96/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.1052e-11\n",
      "Epoch 97/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.1363e-11\n",
      "Epoch 98/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.1763e-11\n",
      "Epoch 99/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.0967e-11\n",
      "Epoch 100/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.6006e-11\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model_b = nn_b.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BaFobo2TW_Kr",
    "outputId": "564d8752-f7fb-47c2-aef7-b4b01df44b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - 1ms/step - accuracy: 1.0000 - loss: 1.2513e-10\n",
      "Loss: 1.2513438896188944e-10, Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn_b.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mgB3rz5vW_Bh",
    "outputId": "e491333c-c26c-4875-fa8a-e6e7226669dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Export our model to HDF5 file - AlphabetSoupCharity.h5\n",
    "nn_b.save('AlphabetSoupCharity_Optomization_b.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nf5L9Aa7W-87"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4UQt-wWYk2H"
   },
   "source": [
    "third model - more neurons up front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "id": "GoU-_2DpW-2n",
    "outputId": "af253c0e-d7ed-4112-e4ea-200bb27e0328"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,050</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">510</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │       \u001b[38;5;34m100,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │     \u001b[38;5;34m1,000,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m25,050\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m510\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m11\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,126,071</span> (4.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,126,071\u001b[0m (4.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,126,071</span> (4.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,126,071\u001b[0m (4.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features_c = len(X_train[0])\n",
    "hidden_nodes_layer1_c =  2000\n",
    "hidden_nodes_layer2_c = 500\n",
    "hidden_nodes_layer3_c = 50\n",
    "hidden_nodes_layer4_c = 10\n",
    "\n",
    "nn_c = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_c.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1_c, input_dim=number_input_features_c, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn_c.add(tf.keras.layers.Dense(units=hidden_nodes_layer2_c, activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Third hidden layer\n",
    "nn_c.add(tf.keras.layers.Dense(units=hidden_nodes_layer3_c, activation=\"relu\"))\n",
    "\n",
    "# fourth hidden layer\n",
    "nn_c.add(tf.keras.layers.Dense(units=hidden_nodes_layer4_c, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_c.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_c.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "nC03J6ccW-rr"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_c.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OEngZv4hW-kI",
    "outputId": "4219f2b6-f83f-4451-c465-1a33ae13729a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.9745 - loss: 0.0789\n",
      "Epoch 2/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9978 - loss: 0.0087\n",
      "Epoch 3/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9983 - loss: 0.0054\n",
      "Epoch 4/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.9991 - loss: 0.0030\n",
      "Epoch 5/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.9987 - loss: 0.0079\n",
      "Epoch 6/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.9993 - loss: 0.0026\n",
      "Epoch 7/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.9993 - loss: 9.5990e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9994 - loss: 0.0017\n",
      "Epoch 9/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9989 - loss: 0.0056\n",
      "Epoch 10/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9995 - loss: 7.3098e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.9994 - loss: 6.7717e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.9994 - loss: 0.0019\n",
      "Epoch 13/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9985 - loss: 0.0132\n",
      "Epoch 14/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9997 - loss: 0.0016\n",
      "Epoch 15/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9998 - loss: 3.0010e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.9995 - loss: 3.6030e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9996 - loss: 3.1088e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 2.3741e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.8721e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.5612e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 2.1900e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.8792e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.0041e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.9194e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.4736e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.6946e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.0983e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.4382e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.0717e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.2827e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 9.4067e-05\n",
      "Epoch 32/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 8.3554e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 9.5286e-05\n",
      "Epoch 34/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 4.5568e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 5.7212e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.0804e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 6.9695e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 3.4392e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 0.9994 - loss: 0.0079\n",
      "Epoch 40/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 0.9994 - loss: 0.0134\n",
      "Epoch 41/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 0.9992 - loss: 0.0049\n",
      "Epoch 42/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.9771e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 0.9999 - loss: 2.0825e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 7.5453e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.0713e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 4.7552e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 6.7662e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 4.9673e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 5.6790e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 6.5403e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 3.8417e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 5.3216e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 3.9306e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.9953e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 4.9048e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 3.8344e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 3.9700e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 3.7353e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 2.3585e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 2.8241e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 3.1910e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 2.0694e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.8324e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.2757e-05\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.2368e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 2.1787e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.0362e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.8270e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 6.5015e-06\n",
      "Epoch 70/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 6.1819e-06\n",
      "Epoch 71/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.1335e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.1092e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 4.7797e-06\n",
      "Epoch 74/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 8.1273e-06\n",
      "Epoch 75/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 7.6109e-06\n",
      "Epoch 76/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.5004e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 7.1359e-06\n",
      "Epoch 78/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.4413e-06\n",
      "Epoch 79/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 5.7656e-06\n",
      "Epoch 80/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 5.2768e-06\n",
      "Epoch 81/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 6.6394e-06\n",
      "Epoch 82/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 7.9105e-06\n",
      "Epoch 83/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 6.0099e-06\n",
      "Epoch 84/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 4.4356e-06\n",
      "Epoch 85/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 4.4178e-06\n",
      "Epoch 86/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 3.7048e-06\n",
      "Epoch 87/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 5.2146e-06\n",
      "Epoch 88/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 4.9317e-06\n",
      "Epoch 89/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 2.9887e-06\n",
      "Epoch 90/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 4.1536e-06\n",
      "Epoch 91/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.8496e-06\n",
      "Epoch 92/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 2.2717e-06\n",
      "Epoch 93/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 2.2128e-06\n",
      "Epoch 94/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.3173e-06\n",
      "Epoch 95/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.2225e-06\n",
      "Epoch 96/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.9680e-06\n",
      "Epoch 97/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 2.2385e-06\n",
      "Epoch 98/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 2.3397e-06\n",
      "Epoch 99/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.6141e-06\n",
      "Epoch 100/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.5958e-06\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model_c = nn_c.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "BTztlnyuW-cv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 1s - 2ms/step - accuracy: 0.9999 - loss: 0.0011\n",
      "Loss: 0.0010643453570082784, Accuracy: 0.9998833537101746\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn_c.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "R0yOjV6NW-Sc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Export our model to HDF5 file - AlphabetSoupCharity.h5\n",
    "nn_c.save('AlphabetSoupCharity_Optomization_c.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q-zR_jcgW92_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJpTZ_V5Y_UO"
   },
   "source": [
    "fourth model - change activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "SfeI6DnGZDOy"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m45\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">451</span> (1.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m451\u001b[0m (1.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">451</span> (1.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m451\u001b[0m (1.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features_d = len(X_train[0])\n",
    "hidden_nodes_layer1_d =  8\n",
    "hidden_nodes_layer2_d = 5\n",
    "\n",
    "nn_d = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_d.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1_d, input_dim=number_input_features_d, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn_d.add(tf.keras.layers.Dense(units=hidden_nodes_layer2_d, activation=\"sigmoid\"))\n",
    "\n",
    "# Output layer\n",
    "nn_d.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "rVRLOi91aJu0"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_d.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "8b-gJXQRaPiH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 734us/step - accuracy: 0.6463 - loss: 0.6255\n",
      "Epoch 2/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.9990 - loss: 0.1071\n",
      "Epoch 3/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - accuracy: 0.9996 - loss: 0.0398\n",
      "Epoch 4/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795us/step - accuracy: 0.9998 - loss: 0.0203\n",
      "Epoch 5/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 956us/step - accuracy: 1.0000 - loss: 0.0116\n",
      "Epoch 6/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 777us/step - accuracy: 1.0000 - loss: 0.0072\n",
      "Epoch 7/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 0.9999 - loss: 0.0048\n",
      "Epoch 8/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 797us/step - accuracy: 1.0000 - loss: 0.0031\n",
      "Epoch 9/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 758us/step - accuracy: 1.0000 - loss: 0.0022\n",
      "Epoch 10/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 745us/step - accuracy: 1.0000 - loss: 0.0014\n",
      "Epoch 11/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 1.0000 - loss: 9.0778e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 1.0000 - loss: 6.1014e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 810us/step - accuracy: 1.0000 - loss: 4.2373e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - accuracy: 1.0000 - loss: 2.7863e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 861us/step - accuracy: 1.0000 - loss: 1.9621e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - accuracy: 1.0000 - loss: 1.3001e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.7513e-05\n",
      "Epoch 18/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - accuracy: 1.0000 - loss: 5.9250e-05\n",
      "Epoch 19/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - accuracy: 1.0000 - loss: 4.1654e-05\n",
      "Epoch 20/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 782us/step - accuracy: 1.0000 - loss: 2.8062e-05\n",
      "Epoch 21/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 745us/step - accuracy: 1.0000 - loss: 1.9209e-05\n",
      "Epoch 22/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 946us/step - accuracy: 1.0000 - loss: 1.3483e-05\n",
      "Epoch 23/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.9582e-06\n",
      "Epoch 24/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 872us/step - accuracy: 1.0000 - loss: 6.0189e-06\n",
      "Epoch 25/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 737us/step - accuracy: 1.0000 - loss: 4.2505e-06\n",
      "Epoch 26/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 782us/step - accuracy: 1.0000 - loss: 2.8688e-06\n",
      "Epoch 27/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.9816e-06\n",
      "Epoch 28/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - accuracy: 1.0000 - loss: 2.5054e-06\n",
      "Epoch 29/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - accuracy: 1.0000 - loss: 2.5031e-06\n",
      "Epoch 30/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 1.0000 - loss: 5.4868e-06\n",
      "Epoch 31/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824us/step - accuracy: 1.0000 - loss: 1.0285e-06\n",
      "Epoch 32/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 1.0000 - loss: 9.8970e-07\n",
      "Epoch 33/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - accuracy: 1.0000 - loss: 9.1335e-07\n",
      "Epoch 34/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 778us/step - accuracy: 1.0000 - loss: 8.9294e-07\n",
      "Epoch 35/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 959us/step - accuracy: 1.0000 - loss: 8.0282e-07\n",
      "Epoch 36/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 938us/step - accuracy: 1.0000 - loss: 7.0584e-07\n",
      "Epoch 37/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 782us/step - accuracy: 1.0000 - loss: 6.2915e-07\n",
      "Epoch 38/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - accuracy: 1.0000 - loss: 5.2228e-07\n",
      "Epoch 39/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 751us/step - accuracy: 1.0000 - loss: 4.2141e-07\n",
      "Epoch 40/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 1.0000 - loss: 3.4413e-07\n",
      "Epoch 41/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 1.0000 - loss: 2.5408e-07\n",
      "Epoch 42/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 723us/step - accuracy: 1.0000 - loss: 1.9706e-07\n",
      "Epoch 43/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 792us/step - accuracy: 1.0000 - loss: 1.3928e-07\n",
      "Epoch 44/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673us/step - accuracy: 1.0000 - loss: 1.0967e-07\n",
      "Epoch 45/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - accuracy: 1.0000 - loss: 8.3128e-08\n",
      "Epoch 46/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 1.0000 - loss: 5.7864e-08\n",
      "Epoch 47/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - accuracy: 1.0000 - loss: 4.6988e-08\n",
      "Epoch 48/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - accuracy: 1.0000 - loss: 4.0580e-08\n",
      "Epoch 49/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - accuracy: 1.0000 - loss: 3.8340e-08\n",
      "Epoch 50/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step - accuracy: 1.0000 - loss: 3.3636e-08\n",
      "Epoch 51/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - accuracy: 1.0000 - loss: 2.7525e-08\n",
      "Epoch 52/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 1.0000 - loss: 2.6645e-08\n",
      "Epoch 53/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - accuracy: 1.0000 - loss: 2.5749e-08\n",
      "Epoch 54/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754us/step - accuracy: 1.0000 - loss: 2.4124e-08\n",
      "Epoch 55/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 775us/step - accuracy: 1.0000 - loss: 1.9995e-08\n",
      "Epoch 56/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 794us/step - accuracy: 1.0000 - loss: 1.9495e-08\n",
      "Epoch 57/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 798us/step - accuracy: 1.0000 - loss: 1.9494e-08\n",
      "Epoch 58/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 791us/step - accuracy: 1.0000 - loss: 1.7405e-08\n",
      "Epoch 59/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786us/step - accuracy: 1.0000 - loss: 1.6902e-08\n",
      "Epoch 60/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 1.0000 - loss: 1.6459e-08\n",
      "Epoch 61/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - accuracy: 1.0000 - loss: 1.5872e-08\n",
      "Epoch 62/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - accuracy: 1.0000 - loss: 1.5112e-08\n",
      "Epoch 63/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 1.0000 - loss: 3.5207e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 732us/step - accuracy: 1.0000 - loss: 1.2881e-08\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 1.0000 - loss: 1.2875e-08\n",
      "Epoch 66/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684us/step - accuracy: 1.0000 - loss: 1.3036e-08\n",
      "Epoch 67/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - accuracy: 1.0000 - loss: 1.2553e-08\n",
      "Epoch 68/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 1.0000 - loss: 1.3952e-08\n",
      "Epoch 69/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 770us/step - accuracy: 1.0000 - loss: 1.2968e-08\n",
      "Epoch 70/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - accuracy: 1.0000 - loss: 1.2570e-08\n",
      "Epoch 71/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - accuracy: 1.0000 - loss: 1.2551e-08\n",
      "Epoch 72/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681us/step - accuracy: 1.0000 - loss: 1.2652e-08\n",
      "Epoch 73/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - accuracy: 1.0000 - loss: 1.3242e-08\n",
      "Epoch 74/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765us/step - accuracy: 1.0000 - loss: 1.2313e-08\n",
      "Epoch 75/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - accuracy: 1.0000 - loss: 1.4056e-08\n",
      "Epoch 76/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680us/step - accuracy: 1.0000 - loss: 1.2355e-08\n",
      "Epoch 77/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673us/step - accuracy: 1.0000 - loss: 1.3174e-08\n",
      "Epoch 78/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 751us/step - accuracy: 1.0000 - loss: 1.2383e-08\n",
      "Epoch 79/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718us/step - accuracy: 1.0000 - loss: 1.2188e-08\n",
      "Epoch 80/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 746us/step - accuracy: 1.0000 - loss: 1.2581e-08\n",
      "Epoch 81/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - accuracy: 1.0000 - loss: 1.1710e-08\n",
      "Epoch 82/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - accuracy: 1.0000 - loss: 1.2423e-08\n",
      "Epoch 83/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - accuracy: 1.0000 - loss: 1.2048e-08\n",
      "Epoch 84/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - accuracy: 1.0000 - loss: 1.1971e-08\n",
      "Epoch 85/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - accuracy: 1.0000 - loss: 1.2118e-08\n",
      "Epoch 86/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.1687e-08\n",
      "Epoch 87/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 997us/step - accuracy: 1.0000 - loss: 1.1511e-08\n",
      "Epoch 88/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 1.0000 - loss: 1.1613e-08\n",
      "Epoch 89/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 872us/step - accuracy: 1.0000 - loss: 1.1401e-08\n",
      "Epoch 90/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 1.0000 - loss: 1.1038e-08\n",
      "Epoch 91/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 800us/step - accuracy: 1.0000 - loss: 1.0497e-08\n",
      "Epoch 92/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 749us/step - accuracy: 1.0000 - loss: 1.0439e-08\n",
      "Epoch 93/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738us/step - accuracy: 1.0000 - loss: 1.0390e-08\n",
      "Epoch 94/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 1.0000 - loss: 9.8569e-09\n",
      "Epoch 95/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - accuracy: 1.0000 - loss: 1.0080e-08\n",
      "Epoch 96/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - accuracy: 1.0000 - loss: 9.9316e-09\n",
      "Epoch 97/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - accuracy: 1.0000 - loss: 9.4631e-09\n",
      "Epoch 98/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - accuracy: 1.0000 - loss: 2.4462e-08\n",
      "Epoch 99/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - accuracy: 1.0000 - loss: 8.2897e-07\n",
      "Epoch 100/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - accuracy: 1.0000 - loss: 1.2695e-08\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model_d = nn_d.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "nB5stq94aRLF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - 859us/step - accuracy: 0.9995 - loss: 0.0055\n",
      "Loss: 0.005535146687179804, Accuracy: 0.9995335340499878\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn_d.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "xUgdrrxyaT1a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Export our model to HDF5 file - AlphabetSoupCharity.h5\n",
    "nn_d.save('AlphabetSoupCharity_Optomization_d.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l9EMM0NJaXlC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:dev]",
   "language": "python",
   "name": "conda-env-dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
